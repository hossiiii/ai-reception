"""
ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã‚µãƒ¼ãƒ“ã‚¹

Phase 3ã®æœ€é©åŒ–æ©Ÿèƒ½:
1. éŸ³å£°å‡¦ç†ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·æœ€å°åŒ–
2. ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æœ€é©åŒ–
3. CPUåŠ¹ç‡æ”¹å–„
4. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¸¯åŸŸå¹…æœ€é©åŒ–
"""

import asyncio
import time
import psutil
import gc
import threading
from typing import Dict, Any, Optional, List, Tuple
from dataclasses import dataclass, field
from collections import deque
import numpy as np
from concurrent.futures import ThreadPoolExecutor
import weakref


@dataclass
class PerformanceMetrics:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
    timestamp: float
    cpu_percent: float
    memory_percent: float
    memory_mb: float
    audio_latency_ms: float
    processing_time_ms: float
    active_sessions: int
    queue_size: int


@dataclass
class AudioBuffer:
    """æœ€é©åŒ–ã•ã‚ŒãŸéŸ³å£°ãƒãƒƒãƒ•ã‚¡"""
    data: bytes
    timestamp: float
    session_id: str
    chunk_id: int
    compressed: bool = False
    
    def __post_init__(self):
        self.size = len(self.data)


class AudioBufferPool:
    """éŸ³å£°ãƒãƒƒãƒ•ã‚¡ãƒ—ãƒ¼ãƒ«ï¼ˆãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ï¼‰"""
    
    def __init__(self, max_buffers: int = 100, max_buffer_size: int = 64 * 1024):
        self.max_buffers = max_buffers
        self.max_buffer_size = max_buffer_size
        self.available_buffers: deque = deque()
        self.active_buffers: weakref.WeakSet = weakref.WeakSet()
        self._lock = threading.Lock()
        
    def get_buffer(self, session_id: str, data: bytes) -> AudioBuffer:
        """ãƒãƒƒãƒ•ã‚¡ã‚’å–å¾—ï¼ˆå†åˆ©ç”¨æœ€é©åŒ–ï¼‰"""
        with self._lock:
            if self.available_buffers and len(data) <= self.max_buffer_size:
                # æ—¢å­˜ãƒãƒƒãƒ•ã‚¡ã‚’å†åˆ©ç”¨
                buffer = self.available_buffers.popleft()
                buffer.data = data
                buffer.session_id = session_id
                buffer.timestamp = time.time()
                buffer.chunk_id = getattr(buffer, 'chunk_id', 0) + 1
            else:
                # æ–°ã—ã„ãƒãƒƒãƒ•ã‚¡ã‚’ä½œæˆ
                buffer = AudioBuffer(
                    data=data,
                    session_id=session_id,
                    timestamp=time.time(),
                    chunk_id=0
                )
            
            self.active_buffers.add(buffer)
            return buffer
    
    def return_buffer(self, buffer: AudioBuffer):
        """ãƒãƒƒãƒ•ã‚¡ã‚’è¿”å´ï¼ˆå†åˆ©ç”¨ã®ãŸã‚ï¼‰"""
        with self._lock:
            if len(self.available_buffers) < self.max_buffers:
                buffer.data = b''  # ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢
                buffer.session_id = ''
                self.available_buffers.append(buffer)
            
            self.active_buffers.discard(buffer)
    
    def cleanup(self):
        """å¤ã„ãƒãƒƒãƒ•ã‚¡ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        current_time = time.time()
        cleanup_threshold = 300  # 5åˆ†
        
        with self._lock:
            # å¤ã„ãƒãƒƒãƒ•ã‚¡ã‚’å‰Šé™¤
            active_buffers_copy = list(self.active_buffers)
            for buffer in active_buffers_copy:
                if current_time - buffer.timestamp > cleanup_threshold:
                    self.active_buffers.discard(buffer)


class AdaptiveAudioProcessor:
    """é©å¿œçš„éŸ³å£°å‡¦ç†ï¼ˆãƒ¬ã‚¤ãƒ†ãƒ³ã‚·æœ€é©åŒ–ï¼‰"""
    
    def __init__(self):
        self.processing_times = deque(maxlen=100)
        self.optimal_chunk_size = 16 * 1024  # åˆæœŸå€¤
        self.min_chunk_size = 4 * 1024
        self.max_chunk_size = 64 * 1024
        self.target_latency_ms = 100
        
    def optimize_chunk_size(self, current_latency_ms: float) -> int:
        """ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã«åŸºã¥ã„ã¦ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã‚’æœ€é©åŒ–"""
        self.processing_times.append(current_latency_ms)
        
        if len(self.processing_times) < 10:
            return self.optimal_chunk_size
        
        avg_latency = sum(self.processing_times) / len(self.processing_times)
        
        if avg_latency > self.target_latency_ms * 1.5:
            # ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãŒé«˜ã„å ´åˆã€ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã‚’å°ã•ãã™ã‚‹
            self.optimal_chunk_size = max(
                self.min_chunk_size,
                int(self.optimal_chunk_size * 0.8)
            )
        elif avg_latency < self.target_latency_ms * 0.7:
            # ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãŒä½ã„å ´åˆã€ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã‚’å¤§ããã™ã‚‹
            self.optimal_chunk_size = min(
                self.max_chunk_size,
                int(self.optimal_chunk_size * 1.2)
            )
        
        return self.optimal_chunk_size
    
    def process_audio_optimized(self, audio_data: bytes, session_id: str) -> Tuple[List[bytes], float]:
        """æœ€é©åŒ–ã•ã‚ŒãŸéŸ³å£°å‡¦ç†"""
        start_time = time.time()
        
        # ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã«åŸºã¥ã„ã¦åˆ†å‰²
        chunk_size = self.optimal_chunk_size
        chunks = []
        
        for i in range(0, len(audio_data), chunk_size):
            chunk = audio_data[i:i + chunk_size]
            chunks.append(chunk)
        
        processing_time = (time.time() - start_time) * 1000
        self.optimize_chunk_size(processing_time)
        
        return chunks, processing_time


class MemoryManager:
    """ãƒ¡ãƒ¢ãƒªç®¡ç†æœ€é©åŒ–"""
    
    def __init__(self, memory_threshold_percent: float = 80.0):
        self.memory_threshold = memory_threshold_percent
        self.cleanup_interval = 60  # 60ç§’é–“éš”
        self.last_cleanup = time.time()
        
    def check_memory_usage(self) -> Dict[str, Any]:
        """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒã‚§ãƒƒã‚¯"""
        memory = psutil.virtual_memory()
        
        return {
            "total_mb": memory.total / 1024 / 1024,
            "used_mb": memory.used / 1024 / 1024,
            "available_mb": memory.available / 1024 / 1024,
            "percent": memory.percent,
            "needs_cleanup": memory.percent > self.memory_threshold
        }
    
    def force_garbage_collection(self) -> Dict[str, Any]:
        """å¼·åˆ¶ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³"""
        before_objects = len(gc.get_objects())
        before_memory = psutil.virtual_memory().used / 1024 / 1024
        
        # ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
        collected = gc.collect()
        
        after_objects = len(gc.get_objects())
        after_memory = psutil.virtual_memory().used / 1024 / 1024
        
        return {
            "collected_objects": collected,
            "objects_before": before_objects,
            "objects_after": after_objects,
            "memory_freed_mb": before_memory - after_memory,
            "memory_before_mb": before_memory,
            "memory_after_mb": after_memory
        }
    
    def should_cleanup(self) -> bool:
        """ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãŒå¿…è¦ã‹ãƒã‚§ãƒƒã‚¯"""
        current_time = time.time()
        memory_info = self.check_memory_usage()
        
        return (
            memory_info["needs_cleanup"] or
            current_time - self.last_cleanup > self.cleanup_interval
        )
    
    def perform_cleanup(self) -> Dict[str, Any]:
        """ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Ÿè¡Œ"""
        if not self.should_cleanup():
            return {"skipped": True, "reason": "cleanup_not_needed"}
        
        cleanup_result = self.force_garbage_collection()
        self.last_cleanup = time.time()
        
        return cleanup_result


class CPUOptimizer:
    """CPUæœ€é©åŒ–"""
    
    def __init__(self, max_workers: Optional[int] = None):
        self.max_workers = max_workers or min(8, psutil.cpu_count())
        self.executor = ThreadPoolExecutor(max_workers=self.max_workers)
        self.cpu_usage_history = deque(maxlen=60)  # 1åˆ†é–“ã®å±¥æ­´
        
    def get_cpu_usage(self) -> float:
        """CPUä½¿ç”¨ç‡å–å¾—"""
        cpu_percent = psutil.cpu_percent(interval=0.1)
        self.cpu_usage_history.append(cpu_percent)
        return cpu_percent
    
    def is_cpu_under_pressure(self) -> bool:
        """CPUè² è·ãŒé«˜ã„ã‹ãƒã‚§ãƒƒã‚¯"""
        if len(self.cpu_usage_history) < 10:
            return False
        
        recent_usage = list(self.cpu_usage_history)[-10:]
        avg_usage = sum(recent_usage) / len(recent_usage)
        
        return avg_usage > 70.0  # 70%ã‚’é–¾å€¤ã¨ã™ã‚‹
    
    def get_optimal_concurrency(self) -> int:
        """æœ€é©ãªä¸¦è¡Œå‡¦ç†æ•°ã‚’è¨ˆç®—"""
        if self.is_cpu_under_pressure():
            return max(1, self.max_workers // 2)
        else:
            return self.max_workers
    
    async def process_async_with_optimization(self, func, *args, **kwargs):
        """æœ€é©åŒ–ã•ã‚ŒãŸéåŒæœŸå‡¦ç†"""
        loop = asyncio.get_event_loop()
        
        if self.is_cpu_under_pressure():
            # CPUè² è·ãŒé«˜ã„å ´åˆã¯é †æ¬¡å‡¦ç†
            return func(*args, **kwargs)
        else:
            # é€šå¸¸æ™‚ã¯ä¸¦è¡Œå‡¦ç†
            return await loop.run_in_executor(self.executor, func, *args, **kwargs)


class NetworkOptimizer:
    """ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æœ€é©åŒ–"""
    
    def __init__(self):
        self.compression_threshold = 1024  # 1KBä»¥ä¸Šã§åœ§ç¸®æ¤œè¨
        self.bandwidth_history = deque(maxlen=30)
        
    def estimate_bandwidth(self, data_size: int, transfer_time: float) -> float:
        """å¸¯åŸŸå¹…æ¨å®š"""
        if transfer_time <= 0:
            return 0
        
        bandwidth_bps = (data_size * 8) / transfer_time  # bits per second
        bandwidth_mbps = bandwidth_bps / 1024 / 1024
        
        self.bandwidth_history.append(bandwidth_mbps)
        return bandwidth_mbps
    
    def should_compress_audio(self, audio_size: int) -> bool:
        """éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’åœ§ç¸®ã™ã¹ãã‹ãƒã‚§ãƒƒã‚¯"""
        if audio_size < self.compression_threshold:
            return False
        
        if len(self.bandwidth_history) < 5:
            return audio_size > 10 * 1024  # 10KBä»¥ä¸Šã§åœ§ç¸®
        
        avg_bandwidth = sum(self.bandwidth_history) / len(self.bandwidth_history)
        
        # å¸¯åŸŸå¹…ãŒä½ã„å ´åˆã¯ç©æ¥µçš„ã«åœ§ç¸®
        return avg_bandwidth < 1.0 or audio_size > 50 * 1024
    
    def optimize_chunk_transmission(self, data: bytes, target_latency_ms: float = 100) -> List[bytes]:
        """ãƒãƒ£ãƒ³ã‚¯è»¢é€æœ€é©åŒ–"""
        if len(self.bandwidth_history) < 3:
            # åˆæœŸçŠ¶æ…‹ã§ã¯æ¨™æº–ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º
            chunk_size = 16 * 1024
        else:
            avg_bandwidth = sum(self.bandwidth_history) / len(self.bandwidth_history)
            
            # å¸¯åŸŸå¹…ã«åŸºã¥ã„ã¦ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã‚’èª¿æ•´
            if avg_bandwidth > 10:  # é«˜å¸¯åŸŸ
                chunk_size = 64 * 1024
            elif avg_bandwidth > 1:  # ä¸­å¸¯åŸŸ
                chunk_size = 32 * 1024
            else:  # ä½å¸¯åŸŸ
                chunk_size = 8 * 1024
        
        chunks = []
        for i in range(0, len(data), chunk_size):
            chunks.append(data[i:i + chunk_size])
        
        return chunks


class PerformanceOptimizer:
    """çµ±åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã‚µãƒ¼ãƒ“ã‚¹"""
    
    def __init__(self):
        self.buffer_pool = AudioBufferPool()
        self.audio_processor = AdaptiveAudioProcessor()
        self.memory_manager = MemoryManager()
        self.cpu_optimizer = CPUOptimizer()
        self.network_optimizer = NetworkOptimizer()
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
        self.metrics_history = deque(maxlen=1000)
        self.optimization_enabled = True
        
        print("âœ… PerformanceOptimizer initialized")
    
    async def optimize_audio_processing(self, audio_data: bytes, session_id: str) -> Dict[str, Any]:
        """éŸ³å£°å‡¦ç†æœ€é©åŒ–"""
        start_time = time.time()
        
        try:
            # ãƒ¡ãƒ¢ãƒªãƒã‚§ãƒƒã‚¯
            if self.memory_manager.should_cleanup():
                cleanup_result = self.memory_manager.perform_cleanup()
                print(f"ğŸ§¹ Memory cleanup: freed {cleanup_result.get('memory_freed_mb', 0):.2f}MB")
            
            # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®æœ€é©åŒ–å‡¦ç†
            buffer = self.buffer_pool.get_buffer(session_id, audio_data)
            
            # CPUã®çŠ¶æ…‹ã«å¿œã˜ã¦å‡¦ç†æ–¹æ³•ã‚’é¸æŠ
            if self.cpu_optimizer.is_cpu_under_pressure():
                # é«˜è² è·æ™‚ã¯ã‚·ãƒ³ãƒ—ãƒ«ãªå‡¦ç†
                chunks, processing_time = await self._simple_audio_processing(audio_data)
            else:
                # é€šå¸¸æ™‚ã¯æœ€é©åŒ–å‡¦ç†
                chunks, processing_time = await self._optimized_audio_processing(audio_data, session_id)
            
            # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æœ€é©åŒ–
            if self.network_optimizer.should_compress_audio(len(audio_data)):
                chunks = await self._compress_audio_chunks(chunks)
                compression_applied = True
            else:
                compression_applied = False
            
            # ãƒãƒƒãƒ•ã‚¡è¿”å´
            self.buffer_pool.return_buffer(buffer)
            
            total_time = (time.time() - start_time) * 1000
            
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²
            await self._record_performance_metrics(total_time, len(audio_data))
            
            return {
                "success": True,
                "chunks": chunks,
                "processing_time_ms": total_time,
                "audio_processing_time_ms": processing_time,
                "compression_applied": compression_applied,
                "chunk_count": len(chunks),
                "optimization_level": "high" if not self.cpu_optimizer.is_cpu_under_pressure() else "conservative"
            }
            
        except Exception as e:
            print(f"âŒ Audio processing optimization error: {e}")
            return {
                "success": False,
                "error": str(e),
                "fallback_processing": True
            }
    
    async def _simple_audio_processing(self, audio_data: bytes) -> Tuple[List[bytes], float]:
        """ã‚·ãƒ³ãƒ—ãƒ«ãªéŸ³å£°å‡¦ç†ï¼ˆé«˜è² è·æ™‚ï¼‰"""
        start_time = time.time()
        
        # å˜ç´”ãªå›ºå®šã‚µã‚¤ã‚ºåˆ†å‰²
        chunk_size = 16 * 1024
        chunks = []
        for i in range(0, len(audio_data), chunk_size):
            chunks.append(audio_data[i:i + chunk_size])
        
        processing_time = (time.time() - start_time) * 1000
        return chunks, processing_time
    
    async def _optimized_audio_processing(self, audio_data: bytes, session_id: str) -> Tuple[List[bytes], float]:
        """æœ€é©åŒ–ã•ã‚ŒãŸéŸ³å£°å‡¦ç†"""
        return await self.cpu_optimizer.process_async_with_optimization(
            self.audio_processor.process_audio_optimized,
            audio_data,
            session_id
        )
    
    async def _compress_audio_chunks(self, chunks: List[bytes]) -> List[bytes]:
        """éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã®åœ§ç¸®"""
        # ç°¡å˜ãªåœ§ç¸®å®Ÿè£…ï¼ˆå®Ÿéš›ã®ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ã‚ˆã‚Šé«˜åº¦ãªåœ§ç¸®ã‚’ä½¿ç”¨ï¼‰
        import zlib
        
        compressed_chunks = []
        for chunk in chunks:
            if len(chunk) > 512:  # å°ã•ãªãƒãƒ£ãƒ³ã‚¯ã¯åœ§ç¸®ã—ãªã„
                try:
                    compressed = zlib.compress(chunk, level=1)  # é«˜é€Ÿåœ§ç¸®
                    if len(compressed) < len(chunk) * 0.9:  # åœ§ç¸®åŠ¹æœãŒã‚ã‚‹ãªã‚‰ä½¿ç”¨
                        compressed_chunks.append(compressed)
                    else:
                        compressed_chunks.append(chunk)
                except:
                    compressed_chunks.append(chunk)
            else:
                compressed_chunks.append(chunk)
        
        return compressed_chunks
    
    async def _record_performance_metrics(self, processing_time_ms: float, audio_size: int):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²"""
        try:
            memory_info = self.memory_manager.check_memory_usage()
            cpu_usage = self.cpu_optimizer.get_cpu_usage()
            
            metrics = PerformanceMetrics(
                timestamp=time.time(),
                cpu_percent=cpu_usage,
                memory_percent=memory_info["percent"],
                memory_mb=memory_info["used_mb"],
                audio_latency_ms=processing_time_ms,
                processing_time_ms=processing_time_ms,
                active_sessions=len(self.buffer_pool.active_buffers),
                queue_size=len(self.buffer_pool.available_buffers)
            )
            
            self.metrics_history.append(metrics)
            
        except Exception as e:
            print(f"âš ï¸ Metrics recording error: {e}")
    
    async def get_performance_summary(self) -> Dict[str, Any]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¦ç´„å–å¾—"""
        if not self.metrics_history:
            return {"error": "No metrics available"}
        
        recent_metrics = list(self.metrics_history)[-10:]  # æœ€æ–°10ä»¶
        
        avg_cpu = sum(m.cpu_percent for m in recent_metrics) / len(recent_metrics)
        avg_memory = sum(m.memory_percent for m in recent_metrics) / len(recent_metrics)
        avg_latency = sum(m.audio_latency_ms for m in recent_metrics) / len(recent_metrics)
        
        return {
            "timestamp": time.time(),
            "optimization_enabled": self.optimization_enabled,
            "performance": {
                "avg_cpu_percent": round(avg_cpu, 2),
                "avg_memory_percent": round(avg_memory, 2),
                "avg_audio_latency_ms": round(avg_latency, 2),
                "current_chunk_size": self.audio_processor.optimal_chunk_size,
                "active_buffers": len(self.buffer_pool.active_buffers),
                "cpu_under_pressure": self.cpu_optimizer.is_cpu_under_pressure()
            },
            "memory": self.memory_manager.check_memory_usage(),
            "network": {
                "bandwidth_history_count": len(self.network_optimizer.bandwidth_history),
                "compression_threshold": self.network_optimizer.compression_threshold
            },
            "optimizations_applied": {
                "adaptive_chunk_sizing": True,
                "memory_pooling": True,
                "cpu_load_balancing": True,
                "network_compression": True
            }
        }
    
    async def adjust_optimization_level(self, level: str) -> Dict[str, Any]:
        """æœ€é©åŒ–ãƒ¬ãƒ™ãƒ«èª¿æ•´"""
        if level == "aggressive":
            self.audio_processor.target_latency_ms = 50
            self.memory_manager.memory_threshold = 90.0
            self.network_optimizer.compression_threshold = 512
            
        elif level == "balanced":
            self.audio_processor.target_latency_ms = 100
            self.memory_manager.memory_threshold = 80.0
            self.network_optimizer.compression_threshold = 1024
            
        elif level == "conservative":
            self.audio_processor.target_latency_ms = 200
            self.memory_manager.memory_threshold = 70.0
            self.network_optimizer.compression_threshold = 2048
            
        return {
            "success": True,
            "optimization_level": level,
            "settings": {
                "target_latency_ms": self.audio_processor.target_latency_ms,
                "memory_threshold": self.memory_manager.memory_threshold,
                "compression_threshold": self.network_optimizer.compression_threshold
            }
        }
    
    async def cleanup_resources(self):
        """ãƒªã‚½ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            # ãƒãƒƒãƒ•ã‚¡ãƒ—ãƒ¼ãƒ«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            self.buffer_pool.cleanup()
            
            # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            cleanup_result = self.memory_manager.perform_cleanup()
            
            # CPUæœ€é©åŒ–ã®ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³
            self.cpu_optimizer.executor.shutdown(wait=False)
            
            print(f"ğŸ§¹ Performance optimizer cleanup completed")
            return {
                "success": True,
                "memory_freed_mb": cleanup_result.get("memory_freed_mb", 0)
            }
            
        except Exception as e:
            print(f"âŒ Cleanup error: {e}")
            return {"success": False, "error": str(e)}


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
performance_optimizer = PerformanceOptimizer()


async def get_performance_optimizer() -> PerformanceOptimizer:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã‚µãƒ¼ãƒ“ã‚¹å–å¾—"""
    return performance_optimizer